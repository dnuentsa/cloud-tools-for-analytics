{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPogLfBo5qiNvOJuSSlUVza",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dnuentsa/cloud-tools-for-analytics/blob/main/notebooks/extract_transform_from_postgres_db.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Purpose of this notebook\n",
        "This notebook shows  how to design a simple data extraction pipeline from a PostgreSQL relational database. The goal is to retrieve structured data from multiple tables, process the information into a meaningful format, and store the results in a CSV file for further use in a data pipeline.\n",
        "\n",
        " Even if it's a simple one, it shows a a real-world data engineering workflow, where raw data is extracted from relational databases, and transformed into a usable format. The resulting CSV file can be used in ETL (Extract, Transform, Load) pipelines, BI Tools to generate Business dashboards or reports, or machine learning models.\n",
        "\n",
        "# Prerequisites to run the notebook\n",
        "- Connect to [https://colab.research.google.com/]() with any Google account.\n",
        "- if you want to use your student Account, you will get redirected to your usual login page. Enter your student credentials\n",
        "- Upload this notebook.\n",
        "- You need to retrieve the credentials to connect to the Postgres database. This is available in the file Datasets/postgres_connection_string.txt on Campus. Open the file and copy the credentials.\n",
        "- On the left panel, Select the Key/Lock icon to add the connection string to connect to your postgres instance.  Adding a secret here instead of inserting it in your python notebook code will prevent you to share your credentials to anyone having access to your source code. or commit your credentials to online repositories such as github.\n",
        "- Select \"Add new secret\"\n",
        "- Use the name postgres_connection_string\n",
        "- Paste the connection string in the \"Value\" Column.\n",
        "- Make sure to toggle ON the column \"Notebook access\"\n",
        "\n",
        "# Database Schema\n",
        "Review the list of available tables in the database and the relationship between them.\n",
        "[Database Schema](https://github.com/dnuentsa/cloud-tools-for-analytics/blob/main/resources/postgresql/database_schema.png)\n",
        "\n",
        "# Main steps\n",
        "Main steps in this notebook include:\n",
        "## Connectin to the Database\n",
        "Establish a secure connection to a remote PostgreSQL database using Pythonâ€™s psycopg2 library.\n",
        "Credentials and connection details are retrieved from your secrets defined above.\n",
        "\n",
        "## Preview the tables\n",
        "Retrieve the list of available tables to understand the database schema.\n",
        "Preview a few rows from each table to get a sense of the data.\n",
        "\n",
        "## Query and Transform Data\n",
        "Extract relevant records from the trips table.\n",
        "Use SQL JOINs to replace foreign key IDs with actual values (e.g., customer names, car details, city names).\n",
        "Convert the data into a structured Pandas DataFrame.\n",
        "\n",
        "## Store the Processed Data\n",
        "Export the cleaned and structured dataset to a CSV file.\n",
        "This file can be used for further data analysis, machine learning, or reporting."
      ],
      "metadata": {
        "id": "45oYa-6OLFYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install psycopg2 pandas sqlalchemy"
      ],
      "metadata": {
        "id": "IVoljcLYSGjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pB6PHpjlKl0l"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "import io\n",
        "import psycopg2\n",
        "import requests\n",
        "\n",
        "# Function to download zip file from a remote location\n",
        "def download_zip(url, save_path):\n",
        "    response = requests.get(url)\n",
        "    with open(save_path, 'wb') as f:\n",
        "        f.write(response.content)\n",
        "\n",
        "\n",
        "\n",
        "# Establish a connection to the database\n",
        "conn = psycopg2.connect(connection_string)\n",
        "\n",
        "# Create a cursor object to execute SQL queries\n",
        "cur = conn.cursor()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import psycopg2\n",
        "import pandas as pd\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "# Retrieve the postgres connection string from secrets\n",
        "from google.colab import userdata\n",
        "connection_string = userdata.get('postgres_connection_string')\n",
        "\n",
        "# Establish Connection to PostgreSQL\n",
        "try:\n",
        "    engine = create_engine(connection_string)\n",
        "    print(\"Connected to the database successfully!\")\n",
        "except Exception as e:\n",
        "    print(\"Failed to connect to the database:\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCEKbEi4WTOA",
        "outputId": "958428fd-a885-418d-d76e-00c9c09dc97e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Connected to the database successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List Tables in the Database\n",
        "query_list_tables = \"\"\"\n",
        "SELECT table_name\n",
        "FROM information_schema.tables\n",
        "WHERE table_schema = 'public';\n",
        "\"\"\"\n",
        "# Read Some Lines from Each Table\n",
        "tables = pd.read_sql(query_list_tables, engine)\n",
        "print(\"ðŸ“‹ Tables in the database:\\n\", tables)\n",
        "table_names = tables[\"table_name\"].tolist()\n",
        "for table in table_names:\n",
        "    query = f\"SELECT * FROM {table} LIMIT 5;\"\n",
        "    print(f\"\\nðŸ”¹ Preview of table: {table}\")\n",
        "    print(pd.read_sql(query, engine))"
      ],
      "metadata": {
        "id": "lLnqVMVMWy2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read Some Lines from Each Table\n",
        "table_names = tables[\"table_name\"].tolist()\n",
        "for table in table_names:\n",
        "    query = f\"SELECT * FROM {table} LIMIT 5;\"\n",
        "    print(f\"\\nðŸ”¹ Preview of table: {table}\")\n",
        "    print(pd.read_sql(query, conn))"
      ],
      "metadata": {
        "id": "bH44aVl9W9j9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read Entire Trips Table with Joins (Using SQLAlchemy)\n",
        "query_trips = \"\"\"\n",
        "SELECT\n",
        "    trips.id, trips.pickup_time, trips.dropoff_time, trips.distance, trips.revenue,\n",
        "    cities.city_name AS trip_city,\n",
        "    customers.name AS customer_name, customers.email,\n",
        "    cars.brand AS car_brand, cars.model AS car_model, cars.year\n",
        "FROM trips\n",
        "JOIN cars ON trips.car_id = cars.id\n",
        "JOIN customers ON trips.customer_id = customers.id\n",
        "JOIN cities ON cars.city_id = cities.city_id;\n",
        "\"\"\"\n",
        "\n",
        "df_trips = pd.read_sql(query_trips, engine)\n",
        "\n",
        "# Preview the DataFrame\n",
        "print(\"\\nPreview of Trips DataFrame:\")\n",
        "print(df_trips.head())"
      ],
      "metadata": {
        "id": "aokcRY2ISBMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Homework Generate some visualizations here from the data in df_trips dataframe.\n",
        "# e.g Revenue per Car Model, Trips per city, ...\n"
      ],
      "metadata": {
        "id": "WRIv0-l3cJCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Homework Get the average trips rating by city in a dataframe\n",
        "query_rating = \"\"\"\n",
        "WRITE THE QUERY TO GET THE AVERAGE RATING PER CITY HERE\n",
        "\"\"\"\n",
        "\n",
        "df_rating = pd.read_sql(query_rating, engine)\n",
        "\n",
        "# Preview the DataFrame\n",
        "print(\"\\nðŸ“Š Preview of Ratings DataFrame:\")\n",
        "# TODO PREVIEW YOUR DATAFRAME HERE"
      ],
      "metadata": {
        "id": "s_Gal5C_j1dn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "QyMUjV8Cmwvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export to CSV and generate a zip file\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "\n",
        "df_trips.to_csv(\"trips_data.csv\", index=False)\n",
        "# TODO Export your ratings per city in a csv file named rating_data.csv\n",
        "\n",
        "\n",
        "# Create a zip file\n",
        "def zip_file(file_path, zip_file_name):\n",
        "    with zipfile.ZipFile(zip_file_name, 'a', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        zipf.write(file_path)\n",
        "    print(f\"\\n'{file_path}' zipped to '{zip_file_name}' successfully!\")\n",
        "\n",
        "# Delete previous zip file\n",
        "zip_file_name = \"exported_data.zip\"\n",
        "if os.path.exists(zip_file_name):\n",
        "    os.remove(zip_file_name)\n",
        "    print(f\"File '{zip_file_name}' deleted successfully.\")\n",
        "\n",
        "zip_file(\"trips_data.csv\", zip_file_name)\n",
        "zip_file(\"rating_data.csv\", zip_file_name)\n",
        "\n",
        "print(\"\\nData exported to 'trips_data.csv' and trips_data.zip successfully!\")\n",
        "\n",
        "# Download the files to your computer\n",
        "from google.colab import files\n",
        "files.download('trips_data.zip')"
      ],
      "metadata": {
        "id": "8tkusClebDZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Free Upp the resources\n",
        "engine.dispose()"
      ],
      "metadata": {
        "id": "Ea-Js7-mYsRO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}