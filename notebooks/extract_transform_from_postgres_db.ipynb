{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYzDkGrk/GM6Q2YFYuJoAT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dnuentsa/cloud-tools-for-analytics/blob/main/notebooks/extract_transform_from_postgres_db.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Purpose of this notebook\n",
        "This notebook shows  how to design a simple data extraction pipeline from a PostgreSQL relational database. The goal is to retrieve structured data from multiple tables, process the information into a meaningful format, and store the results in a CSV file for further use in a data pipeline.\n",
        "\n",
        " Even if it's a simple one, it shows a a real-world data engineering workflow, where raw data is extracted from relational databases, and transformed into a usable format. The resulting CSV file can be used in ETL (Extract, Transform, Load) pipelines, BI Tools to generate Business dashboards or reports, or machine learning models.\n",
        "\n",
        "# Prerequisites to run the notebook\n",
        "- Connect to [https://colab.research.google.com/]() with any Google account.\n",
        "- if you want to use your student Account, you will get redirected to your usual login page. Enter your student credentials\n",
        "- Upload this notebook.\n",
        "- You need to retrieve the credentials to connect to the Postgres database. This is available in the file Datasets/postgres_connection_string.txt on Campus. Open the file and copy the credentials.\n",
        "- On the left panel, Select the Key/Lock icon to add the connection string to connect to your postgres instance.  Adding a secret here instead of inserting it in your python notebook code will prevent you to share your credentials to anyone having access to your source code. or commit your credentials to online repositories such as github.\n",
        "- Select \"Add new secret\"\n",
        "- Use the name postgres_connection_string\n",
        "- Paste the connection string in the \"Value\" Column.\n",
        "- Make sure to toggle ON the column \"Notebook access\"\n",
        "\n",
        "# Main steps\n",
        "Main steps in this notebook include:\n",
        "## Connectin to the Database\n",
        "Establish a secure connection to a remote PostgreSQL database using Python‚Äôs psycopg2 library.\n",
        "Credentials and connection details are retrieved from your secrets defined above.\n",
        "\n",
        "## Explore the Database Structure\n",
        "Retrieve the list of available tables to understand the database schema.\n",
        "Preview a few rows from each table to get a sense of the data.\n",
        "\n",
        "## Query and Transform Data\n",
        "Extract relevant records from the trips table.\n",
        "Use SQL JOINs to replace foreign key IDs with actual values (e.g., customer names, car details, city names).\n",
        "Convert the data into a structured Pandas DataFrame.\n",
        "\n",
        "## Store the Processed Data\n",
        "Export the cleaned and structured dataset to a CSV file.\n",
        "This file can be used for further data analysis, machine learning, or reporting.\n",
        "To download it, you need to"
      ],
      "metadata": {
        "id": "45oYa-6OLFYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install psycopg2 pandas sqlalchemy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVoljcLYSGjl",
        "outputId": "623f43ba-9420-4137-c0bc-f8a0c476eb9b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: psycopg2 in /usr/local/lib/python3.11/dist-packages (2.9.10)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.11/dist-packages (2.0.39)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pB6PHpjlKl0l"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "import io\n",
        "import psycopg2\n",
        "import requests\n",
        "\n",
        "# Function to download zip file from a remote location\n",
        "def download_zip(url, save_path):\n",
        "    response = requests.get(url)\n",
        "    with open(save_path, 'wb') as f:\n",
        "        f.write(response.content)\n",
        "\n",
        "\n",
        "\n",
        "# Establish a connection to the database\n",
        "conn = psycopg2.connect(connection_string)\n",
        "\n",
        "# Create a cursor object to execute SQL queries\n",
        "cur = conn.cursor()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import psycopg2\n",
        "import pandas as pd\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "# Retrieve the postgres connection string from secrets\n",
        "from google.colab import userdata\n",
        "connection_string = userdata.get('postgres_connection_string')\n",
        "\n",
        "# Establish Connection to PostgreSQL\n",
        "try:\n",
        "    engine = create_engine(connection_string)\n",
        "    print(\"‚úÖ Connected to the database successfully!\")\n",
        "except Exception as e:\n",
        "    print(\"‚ùå Failed to connect to the database:\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCEKbEi4WTOA",
        "outputId": "082b3474-c4c1-43a3-9289-0eb04fcd7b34"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Connected to the database successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List Tables in the Database (Now Using SQLAlchemy)\n",
        "query_list_tables = \"\"\"\n",
        "SELECT table_name\n",
        "FROM information_schema.tables\n",
        "WHERE table_schema = 'public';\n",
        "\"\"\"\n",
        "# Read Some Lines from Each Table\n",
        "tables = pd.read_sql(query_list_tables, engine)\n",
        "print(\"üìã Tables in the database:\\n\", tables)\n",
        "table_names = tables[\"table_name\"].tolist()\n",
        "for table in table_names:\n",
        "    query = f\"SELECT * FROM {table} LIMIT 5;\"\n",
        "    print(f\"\\nüîπ Preview of table: {table}\")\n",
        "    print(pd.read_sql(query, engine))"
      ],
      "metadata": {
        "id": "lLnqVMVMWy2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read Some Lines from Each Table\n",
        "table_names = tables[\"table_name\"].tolist()\n",
        "for table in table_names:\n",
        "    query = f\"SELECT * FROM {table} LIMIT 5;\"\n",
        "    print(f\"\\nüîπ Preview of table: {table}\")\n",
        "    print(pd.read_sql(query, conn))"
      ],
      "metadata": {
        "id": "bH44aVl9W9j9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO Get the average trips rating by city. Review the database schema to understand the relationship between all tables\n"
      ],
      "metadata": {
        "id": "fd9By0rXbyU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read Entire Trips Table with Joins (Using SQLAlchemy)\n",
        "query_trips = \"\"\"\n",
        "SELECT\n",
        "    trips.id, trips.pickup_time, trips.dropoff_time, trips.distance, trips.revenue,\n",
        "    cities.city_name AS trip_city,\n",
        "    customers.name AS customer_name, customers.email,\n",
        "    cars.brand AS car_brand, cars.model AS car_model, cars.year\n",
        "FROM trips\n",
        "JOIN cars ON trips.car_id = cars.id\n",
        "JOIN customers ON trips.customer_id = customers.id\n",
        "JOIN cities ON cars.city_id = cities.city_id;\n",
        "\"\"\"\n",
        "\n",
        "df_trips = pd.read_sql(query_trips, engine)\n",
        "\n",
        "# Preview the DataFrame\n",
        "print(\"\\nüìä Preview of Trips DataFrame:\")\n",
        "print(df_trips.head())"
      ],
      "metadata": {
        "id": "aokcRY2ISBMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO Generate some visualizations here from the data in df_trips dataframe."
      ],
      "metadata": {
        "id": "WRIv0-l3cJCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export to CSV\n",
        "df_trips.to_csv(\"trips_data.csv\", index=False)\n",
        "print(\"\\n‚úÖ Data exported to 'trips_data.csv' successfully!\")"
      ],
      "metadata": {
        "id": "8tkusClebDZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Free Upp the resources\n",
        "engine.dispose()"
      ],
      "metadata": {
        "id": "Ea-Js7-mYsRO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}